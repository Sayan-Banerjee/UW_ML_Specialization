{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment from product reviews\n",
    "The goal of this assignment is to explore logistic regression and feature engineering with existing GraphLab Create functions.\n",
    "\n",
    "In this assignment, you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative. You will:\n",
    "\n",
    "Use SFrames to do some feature engineering Train a logistic regression model to predict the sentiment of product reviews. Inspect the weights (coefficients) of a trained logistic regression model. Make a prediction (both class and probability) of sentiment for a new product review. Given the logistic regression weights, predictors and ground truth labels, write a function to compute the accuracy of the model. Inspect the coefficients of the logistic regression model and interpret their meanings. Compare multiple logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform text cleaning\n",
    "We start by removing punctuation, so that words \"cake.\" and \"cake!\" are counted as the same word.\n",
    "\n",
    "Write a function remove_punctuation that strips punctuation from a line of text Apply this function to every element in the review column of products, and save the result to a new column review_clean. Refer to your tool's manual for string processing capabilities. Python lets us express the operation in a succinct way, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['review_clean'] = products['review'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Sentiments\n",
    "We will ignore all reviews with rating = 3, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label. A good way is to create an anonymous function that converts a rating into a class label and then apply that function to every element in the rating column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "1  it came early and was not disappointed i love ...          1  \n",
       "2  Very soft and comfortable and warmer than it l...          1  \n",
       "3  This is a product well worth the purchase  I h...          1  \n",
       "4  All of my kids have cried nonstop when I tried...          1  \n",
       "5  When the Binky Fairy came to our house we didn...          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def readjson(path):\n",
    "    try:\n",
    "        with open(path,'r') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError( \"Please check the path and try agaian!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = readjson(path='module-2-assignment-train-idx.json')\n",
    "test_list = readjson(path='module-2-assignment-test-idx.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = products.iloc[train_list].copy(deep=True)\n",
    "test_data = products.iloc[test_list].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction. Compute the occurrences of the words in each review and collect them into a row vector. Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix. Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a sentiment classifier with logistic regression\n",
    "We will now use logistic regression to create a sentiment classifier on the training data.\n",
    "\n",
    "Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = LogisticRegression()\n",
    "sentiment_model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question: How many weights are >= 0?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85759\n"
     ]
    }
   ],
   "source": [
    "print (np.sum(sum(sentiment_model.coef_ >= 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with logistic regression\n",
    "Now that a model is trained, we can make predictions on the test data. In this section, we will explore this in the context of 3 data points in the test data. Take the 11th, 12th, and 13th data points in the test data and save them to sample_test_data. The following cell extracts the three data points from the SFrame test_data and print their content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely love it and all of the Scripture in it  I purchased the Baby Boy version for my grandson when he was born and my daughterinlaw was thrilled to receive the same book again\n",
      "\n",
      "Would not purchase again or recommend The decals were thick almost plastic like and were coming off the wall as I was applying them The would NOT stick Literally stayed stuck for about 5 minutes then started peeling off\n",
      "\n",
      "Was so excited to get this product for my baby girls bedroom  When I got it the back is NOT STICKY at all  Every time I walked into the bedroom I was picking up pieces off of the floor  Very very frustrating  Ended up having to super glue it to the wallvery disappointing  I wouldnt waste the time or money on it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13].copy(deep=True)\n",
    "for i in sample_test_data.index:\n",
    "    print (sample_test_data.loc[i]['review_clean'], end = '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.59930746  -3.14046638 -10.40387188]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciting Sentiment\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "Using scores, write code to calculate predicted labels for sample_test_data.\n",
    "\n",
    "Checkpoint: Make sure your class predictions match with the ones obtained from sentiment_model. The logistic regression classifier in scikit-learn comes with the predict function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Predictions\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "\n",
    "Using the scores calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range [0, 1].\n",
    "\n",
    "Checkpoint: Make sure your probability predictions match the ones obtained from sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = 1/(1+np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.96313217e-01, 4.14685772e-02, 3.03139609e-05])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most positive (and negative) review\n",
    "We now turn to examining the full test dataset, test_data, and use sklearn.linear_model.LogisticRegression to form predictions on all of the test data points.\n",
    "\n",
    "Using the sentiment_model, find the 20 reviews in the entire test_data with the highest probability of being classified as a positive review. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "\n",
    "Make probability predictions on test_data using the sentiment_model. Sort the data according to those predictions and pick the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "scores_test = sentiment_model.decision_function(test_matrix)\n",
    "predictions = 1/(1+np.exp(-scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'review', 'rating', 'review_clean', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180646</th>\n",
       "      <td>Mamas &amp;amp; Papas 2014 Urbo2 Stroller - Black</td>\n",
       "      <td>After much research I purchased an Urbo2. It's...</td>\n",
       "      <td>4</td>\n",
       "      <td>After much research I purchased an Urbo2 Its e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87017</th>\n",
       "      <td>Baby Einstein Around The World Discovery Center</td>\n",
       "      <td>I am so HAPPY I brought this item for my 7 mon...</td>\n",
       "      <td>5</td>\n",
       "      <td>I am so HAPPY I brought this item for my 7 mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147949</th>\n",
       "      <td>Baby Jogger City Mini GT Single Stroller, Shad...</td>\n",
       "      <td>Amazing, Love, Love, Love it !!! All 5 STARS a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing Love Love Love it  All 5 STARS all the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97325</th>\n",
       "      <td>Freemie Hands-Free Concealable Breast Pump Col...</td>\n",
       "      <td>I absolutely love this product.  I work as a C...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love this product  I work as a Cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168081</th>\n",
       "      <td>Buttons Cloth Diaper Cover - One Size - 8 Colo...</td>\n",
       "      <td>We are big Best Bottoms fans here, but I wante...</td>\n",
       "      <td>4</td>\n",
       "      <td>We are big Best Bottoms fans here but I wanted...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119182</th>\n",
       "      <td>Roan Rocco Classic Pram Stroller 2-in-1 with B...</td>\n",
       "      <td>Great Pram Rocco!!!!!!I bought this pram from ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Pram RoccoI bought this pram from Europe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52631</th>\n",
       "      <td>Evenflo X Sport Plus Convenience Stroller - Ch...</td>\n",
       "      <td>After seeing this in Parent's Magazine and rea...</td>\n",
       "      <td>5</td>\n",
       "      <td>After seeing this in Parents Magazine and read...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66059</th>\n",
       "      <td>Evenflo 6 Pack Classic Glass Bottle, 4-Ounce</td>\n",
       "      <td>It's always fun to write a review on those pro...</td>\n",
       "      <td>5</td>\n",
       "      <td>Its always fun to write a review on those prod...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114796</th>\n",
       "      <td>Fisher-Price Cradle 'N Swing,  My Little Snuga...</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168697</th>\n",
       "      <td>Graco FastAction Fold Jogger Click Connect Str...</td>\n",
       "      <td>Graco's FastAction Jogging Stroller definitely...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gracos FastAction Jogging Stroller definitely ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133651</th>\n",
       "      <td>Britax 2012 B-Agile Stroller, Red</td>\n",
       "      <td>[I got this stroller for my daughter prior to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>I got this stroller for my daughter prior to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80155</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>I just tried this hands free breastpump bra, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>I just tried this hands free breastpump bra an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50315</th>\n",
       "      <td>P'Kolino Silly Soft Seating in Tias, Green</td>\n",
       "      <td>I've purchased both the P'Kolino Little Reader...</td>\n",
       "      <td>4</td>\n",
       "      <td>Ive purchased both the PKolino Little Reader C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137034</th>\n",
       "      <td>Graco Pack 'n Play Element Playard - Flint</td>\n",
       "      <td>My husband and I assembled this Pack n' Play l...</td>\n",
       "      <td>4</td>\n",
       "      <td>My husband and I assembled this Pack n Play la...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100166</th>\n",
       "      <td>Infantino Wrap and Tie Baby Carrier, Black Blu...</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140816</th>\n",
       "      <td>Diono RadianRXT Convertible Car Seat, Plum</td>\n",
       "      <td>I bought this seat for my tall (38in) and thin...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this seat for my tall 38in and thin 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165593</th>\n",
       "      <td>Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...</td>\n",
       "      <td>For the price this set is unbelievable- and tr...</td>\n",
       "      <td>5</td>\n",
       "      <td>For the price this set is unbelievable and tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22586</th>\n",
       "      <td>Britax Decathlon Convertible Car Seat, Tiffany</td>\n",
       "      <td>I researched a few different seats to put in o...</td>\n",
       "      <td>4</td>\n",
       "      <td>I researched a few different seats to put in o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147996</th>\n",
       "      <td>Baby Jogger City Mini GT Double Stroller, Shad...</td>\n",
       "      <td>We are well pleased with this stroller, and I ...</td>\n",
       "      <td>4</td>\n",
       "      <td>We are well pleased with this stroller and I w...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182089</th>\n",
       "      <td>Summer Infant Wide View Digital Color Video Mo...</td>\n",
       "      <td>I love this baby monitor.  I can compare this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this baby monitor  I can compare this o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "180646      Mamas &amp; Papas 2014 Urbo2 Stroller - Black   \n",
       "87017     Baby Einstein Around The World Discovery Center   \n",
       "147949  Baby Jogger City Mini GT Single Stroller, Shad...   \n",
       "97325   Freemie Hands-Free Concealable Breast Pump Col...   \n",
       "168081  Buttons Cloth Diaper Cover - One Size - 8 Colo...   \n",
       "119182  Roan Rocco Classic Pram Stroller 2-in-1 with B...   \n",
       "52631   Evenflo X Sport Plus Convenience Stroller - Ch...   \n",
       "66059        Evenflo 6 Pack Classic Glass Bottle, 4-Ounce   \n",
       "114796  Fisher-Price Cradle 'N Swing,  My Little Snuga...   \n",
       "168697  Graco FastAction Fold Jogger Click Connect Str...   \n",
       "133651                  Britax 2012 B-Agile Stroller, Red   \n",
       "80155   Simple Wishes Hands-Free Breastpump Bra, Pink,...   \n",
       "50315          P'Kolino Silly Soft Seating in Tias, Green   \n",
       "137034         Graco Pack 'n Play Element Playard - Flint   \n",
       "100166  Infantino Wrap and Tie Baby Carrier, Black Blu...   \n",
       "140816         Diono RadianRXT Convertible Car Seat, Plum   \n",
       "165593  Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...   \n",
       "22586      Britax Decathlon Convertible Car Seat, Tiffany   \n",
       "147996  Baby Jogger City Mini GT Double Stroller, Shad...   \n",
       "182089  Summer Infant Wide View Digital Color Video Mo...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "180646  After much research I purchased an Urbo2. It's...       4   \n",
       "87017   I am so HAPPY I brought this item for my 7 mon...       5   \n",
       "147949  Amazing, Love, Love, Love it !!! All 5 STARS a...       5   \n",
       "97325   I absolutely love this product.  I work as a C...       5   \n",
       "168081  We are big Best Bottoms fans here, but I wante...       4   \n",
       "119182  Great Pram Rocco!!!!!!I bought this pram from ...       5   \n",
       "52631   After seeing this in Parent's Magazine and rea...       5   \n",
       "66059   It's always fun to write a review on those pro...       5   \n",
       "114796  My husband and I cannot state enough how much ...       5   \n",
       "168697  Graco's FastAction Jogging Stroller definitely...       5   \n",
       "133651  [I got this stroller for my daughter prior to ...       4   \n",
       "80155   I just tried this hands free breastpump bra, a...       5   \n",
       "50315   I've purchased both the P'Kolino Little Reader...       4   \n",
       "137034  My husband and I assembled this Pack n' Play l...       4   \n",
       "100166  I bought this carrier when my daughter was abo...       5   \n",
       "140816  I bought this seat for my tall (38in) and thin...       5   \n",
       "165593  For the price this set is unbelievable- and tr...       5   \n",
       "22586   I researched a few different seats to put in o...       4   \n",
       "147996  We are well pleased with this stroller, and I ...       4   \n",
       "182089  I love this baby monitor.  I can compare this ...       5   \n",
       "\n",
       "                                             review_clean  sentiment  \\\n",
       "180646  After much research I purchased an Urbo2 Its e...          1   \n",
       "87017   I am so HAPPY I brought this item for my 7 mon...          1   \n",
       "147949  Amazing Love Love Love it  All 5 STARS all the...          1   \n",
       "97325   I absolutely love this product  I work as a Cu...          1   \n",
       "168081  We are big Best Bottoms fans here but I wanted...          1   \n",
       "119182  Great Pram RoccoI bought this pram from Europe...          1   \n",
       "52631   After seeing this in Parents Magazine and read...          1   \n",
       "66059   Its always fun to write a review on those prod...          1   \n",
       "114796  My husband and I cannot state enough how much ...          1   \n",
       "168697  Gracos FastAction Jogging Stroller definitely ...          1   \n",
       "133651  I got this stroller for my daughter prior to t...          1   \n",
       "80155   I just tried this hands free breastpump bra an...          1   \n",
       "50315   Ive purchased both the PKolino Little Reader C...          1   \n",
       "137034  My husband and I assembled this Pack n Play la...          1   \n",
       "100166  I bought this carrier when my daughter was abo...          1   \n",
       "140816  I bought this seat for my tall 38in and thin 2...          1   \n",
       "165593  For the price this set is unbelievable and tru...          1   \n",
       "22586   I researched a few different seats to put in o...          1   \n",
       "147996  We are well pleased with this stroller and I w...          1   \n",
       "182089  I love this baby monitor  I can compare this o...          1   \n",
       "\n",
       "        predictions  \n",
       "180646          1.0  \n",
       "87017           1.0  \n",
       "147949          1.0  \n",
       "97325           1.0  \n",
       "168081          1.0  \n",
       "119182          1.0  \n",
       "52631           1.0  \n",
       "66059           1.0  \n",
       "114796          1.0  \n",
       "168697          1.0  \n",
       "133651          1.0  \n",
       "80155           1.0  \n",
       "50315           1.0  \n",
       "137034          1.0  \n",
       "100166          1.0  \n",
       "140816          1.0  \n",
       "165593          1.0  \n",
       "22586           1.0  \n",
       "147996          1.0  \n",
       "182089          1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sort_values('predictions', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>We have not had ANY luck with Fisher-Price pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>We have not had ANY luck with FisherPrice prod...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.781182e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120209</th>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.899745e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.962844e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.391760e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.637989e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94560</th>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "      <td>Note: we never installed batteries in these un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Note we never installed batteries in these uni...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.619406e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53207</th>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.366419e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81332</th>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.175884e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.690073e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "      <td>It's 3am in the morning and needless to say, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Its 3am in the morning and needless to say thi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.120701e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.359208e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59546</th>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.816373e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75994</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>2</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.509351e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172090</th>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>2</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.673413e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40079</th>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.961684e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149987</th>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "      <td>It thought this would be great. I did a lot of...</td>\n",
       "      <td>1</td>\n",
       "      <td>It thought this would be great I did a lot of ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.969108e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154878</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "      <td>First, the distance on these are no more than ...</td>\n",
       "      <td>1</td>\n",
       "      <td>First the distance on these are no more than 7...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.732424e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.098247e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83234</th>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "      <td>My Experience: Babykicks Inserts failure vs RA...</td>\n",
       "      <td>5</td>\n",
       "      <td>My Experience Babykicks Inserts failure vs RAV...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.640016e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.668114e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "16042         Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "120209  Levana Safe N'See Digital Video Baby Monitor w...   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "94560   The First Years True Choice P400 Premium Digit...   \n",
       "53207                 Safety 1st High-Def Digital Monitor   \n",
       "81332               Cloth Diaper Sprayer--styles may vary   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "10677                   Philips AVENT Newborn Starter Set   \n",
       "9915         Cosco Alpha Omega Elite Convertible Car Seat   \n",
       "59546              Ellaroo Mei Tai Baby Carrier - Hershey   \n",
       "75994          Peg-Perego Tatamia High Chair, White Latte   \n",
       "172090  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...   \n",
       "40079   Chicco Cortina KeyFit 30 Travel System in Adve...   \n",
       "149987                   NUK Cook-n-Blend Baby Food Maker   \n",
       "154878  VTech Communications Safe &amp; Sound Digital ...   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "83234       Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs   \n",
       "31741              Regalo My Cot Portable Bed, Royal Blue   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "16042   We have not had ANY luck with Fisher-Price pro...       2   \n",
       "120209  This is the first review I have ever written o...       1   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "94560   Note: we never installed batteries in these un...       1   \n",
       "53207   We bought this baby monitor to replace a diffe...       1   \n",
       "81332   I bought this sprayer out of desperation durin...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "10677   It's 3am in the morning and needless to say, t...       1   \n",
       "9915    I bought this car seat after both seeing  the ...       1   \n",
       "59546   This is basically an overpriced piece of fabri...       1   \n",
       "75994   I can see why there are so many good reviews o...       2   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...       2   \n",
       "40079   My wife and I have used this system in two car...       1   \n",
       "149987  It thought this would be great. I did a lot of...       1   \n",
       "154878  First, the distance on these are no more than ...       1   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "83234   My Experience: Babykicks Inserts failure vs RA...       5   \n",
       "31741   If I could give this product zero stars I woul...       1   \n",
       "\n",
       "                                             review_clean  sentiment  \\\n",
       "16042   We have not had ANY luck with FisherPrice prod...         -1   \n",
       "120209  This is the first review I have ever written o...         -1   \n",
       "77072   I thought it sounded great to have different t...         -1   \n",
       "48694   I will try to write an objective review of the...         -1   \n",
       "155287  This is my second video monitoring system the ...         -1   \n",
       "94560   Note we never installed batteries in these uni...         -1   \n",
       "53207   We bought this baby monitor to replace a diffe...         -1   \n",
       "81332   I bought this sprayer out of desperation durin...         -1   \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...         -1   \n",
       "10677   Its 3am in the morning and needless to say thi...         -1   \n",
       "9915    I bought this car seat after both seeing  the ...         -1   \n",
       "59546   This is basically an overpriced piece of fabri...         -1   \n",
       "75994   I can see why there are so many good reviews o...         -1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...         -1   \n",
       "40079   My wife and I have used this system in two car...         -1   \n",
       "149987  It thought this would be great I did a lot of ...         -1   \n",
       "154878  First the distance on these are no more than 7...         -1   \n",
       "1116    This item is junk  I originally chose it becau...         -1   \n",
       "83234   My Experience Babykicks Inserts failure vs RAV...          1   \n",
       "31741   If I could give this product zero stars I woul...         -1   \n",
       "\n",
       "         predictions  \n",
       "16042   8.781182e-16  \n",
       "120209  1.899745e-15  \n",
       "77072   7.962844e-14  \n",
       "48694   1.391760e-13  \n",
       "155287  1.637989e-13  \n",
       "94560   4.619406e-13  \n",
       "53207   3.366419e-11  \n",
       "81332   4.175884e-11  \n",
       "113995  9.690073e-11  \n",
       "10677   1.120701e-10  \n",
       "9915    4.359208e-10  \n",
       "59546   4.816373e-10  \n",
       "75994   6.509351e-10  \n",
       "172090  6.673413e-10  \n",
       "40079   6.961684e-10  \n",
       "149987  7.969108e-10  \n",
       "154878  8.732424e-10  \n",
       "1116    1.098247e-09  \n",
       "83234   1.640016e-09  \n",
       "31741   1.668114e-09  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sort_values('predictions', ascending = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute accuracy of the classifier\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "Step 1: Use the sentiment_model to compute class predictions.\n",
    "\n",
    "Step 2: Count the number of data points when the predicted class labels match the ground truth labels.\n",
    "\n",
    "Step 3: Divide the total number of correct predictions by the total number of data points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiment = sentiment_model.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['predicted_sentiment'] = predicted_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['diff_sentiment'] = predicted_sentiment - test_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31082\n"
     ]
    }
   ],
   "source": [
    "acc = np.sum(sum(test_data['diff_sentiment'] == 0))\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33336\n"
     ]
    }
   ],
   "source": [
    "total = len(test_data.index)\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    }
   ],
   "source": [
    "print (round(float(acc)/float(total),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn another classifier with fewer words\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subet of words that occur in the reviews. For this assignment, we selected 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The CountVectorizer class has a parameter that lets you limit the choice of words when building word count vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression model on a subset of data\n",
    "Now build a logistic regression classifier with train_matrix_word_subset as features and sentiment as the target.\n",
    "\n",
    "Call this model simple_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the weights (coefficients) of the simple_model. First, build a table to store (word, coefficient) pairs. If you are using SFrame with scikit-learn, you can combine words with coefficients by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.36368976,  0.94399959,  1.19253827,  0.08551278,  0.52018576,\n",
       "        1.50981248,  1.67307389,  0.50376046,  0.19090857,  0.05885467,\n",
       "       -1.65157634, -0.20956286, -0.51137963, -2.03369861, -2.34829822,\n",
       "       -0.62116877, -0.32055624, -0.89803074, -0.36216674, -2.10933109])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_coef_table = pd.DataFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.673074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perfect</td>\n",
       "      <td>1.509812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>1.363690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>easy</td>\n",
       "      <td>1.192538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>0.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>0.520186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>0.503760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>0.190909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.085513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>0.058855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>less</td>\n",
       "      <td>-0.209563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product</td>\n",
       "      <td>-0.320556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.362167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>even</td>\n",
       "      <td>-0.511380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.621169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.898031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>broke</td>\n",
       "      <td>-1.651576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>waste</td>\n",
       "      <td>-2.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>return</td>\n",
       "      <td>-2.109331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-2.348298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficient\n",
       "6          loves     1.673074\n",
       "5        perfect     1.509812\n",
       "0           love     1.363690\n",
       "2           easy     1.192538\n",
       "1          great     0.944000\n",
       "4         little     0.520186\n",
       "7           well     0.503760\n",
       "8           able     0.190909\n",
       "3            old     0.085513\n",
       "9            car     0.058855\n",
       "11          less    -0.209563\n",
       "16       product    -0.320556\n",
       "18         would    -0.362167\n",
       "12          even    -0.511380\n",
       "15          work    -0.621169\n",
       "17         money    -0.898031\n",
       "10         broke    -1.651576\n",
       "13         waste    -2.033699\n",
       "19        return    -2.109331\n",
       "14  disappointed    -2.348298"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coef_table.sort_values('coefficient',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(simple_model_coef_table['coefficient']>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'came',\n",
       " 'early',\n",
       " 'and',\n",
       " 'was',\n",
       " 'not',\n",
       " 'disappointed',\n",
       " 'i',\n",
       " 'love',\n",
       " 'planet',\n",
       " 'wise',\n",
       " 'bags',\n",
       " 'now',\n",
       " 'my',\n",
       " 'wipe',\n",
       " 'holder',\n",
       " 'keps',\n",
       " 'osocozy',\n",
       " 'wipes',\n",
       " 'moist',\n",
       " 'does',\n",
       " 'leak',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'very',\n",
       " 'soft',\n",
       " 'comfortable',\n",
       " 'warmer',\n",
       " 'than',\n",
       " 'looksfit',\n",
       " 'the',\n",
       " 'full',\n",
       " 'size',\n",
       " 'bed',\n",
       " 'perfectlywould',\n",
       " 'to',\n",
       " 'anyone',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'this',\n",
       " 'type',\n",
       " 'of',\n",
       " 'quilt',\n",
       " 'is',\n",
       " 'a',\n",
       " 'product',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'purchase',\n",
       " 'have',\n",
       " 'found',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'like',\n",
       " 'positive',\n",
       " 'ingenious',\n",
       " 'approach',\n",
       " 'losing',\n",
       " 'binky',\n",
       " 'what',\n",
       " 'most',\n",
       " 'about',\n",
       " 'how',\n",
       " 'much',\n",
       " 'ownership',\n",
       " 'daughter',\n",
       " 'has',\n",
       " 'in',\n",
       " 'getting',\n",
       " 'rid',\n",
       " 'she',\n",
       " 'so',\n",
       " 'proud',\n",
       " 'herself',\n",
       " 'loves',\n",
       " 'her',\n",
       " 'little',\n",
       " 'fairy',\n",
       " 'artwork',\n",
       " 'chart',\n",
       " 'back',\n",
       " 'clever',\n",
       " 'tool',\n",
       " 'all',\n",
       " 'kids',\n",
       " 'cried',\n",
       " 'nonstop',\n",
       " 'when',\n",
       " 'tried',\n",
       " 'ween',\n",
       " 'them',\n",
       " 'off',\n",
       " 'their',\n",
       " 'pacifier',\n",
       " 'until',\n",
       " 'thumbuddy',\n",
       " 'puppet',\n",
       " 'an',\n",
       " 'easy',\n",
       " 'way',\n",
       " 'work',\n",
       " 'with',\n",
       " 'your',\n",
       " 'allow',\n",
       " 'understand',\n",
       " 'where',\n",
       " 'going',\n",
       " 'help',\n",
       " 'part',\n",
       " 'from',\n",
       " 'itthis',\n",
       " 'must',\n",
       " 'buy',\n",
       " 'book',\n",
       " 'great',\n",
       " 'gift',\n",
       " 'expecting',\n",
       " 'parents',\n",
       " 'you',\n",
       " 'will',\n",
       " 'save',\n",
       " 'soo',\n",
       " 'many',\n",
       " 'headachesthanks',\n",
       " 'rock',\n",
       " 'our',\n",
       " 'house',\n",
       " 'we',\n",
       " 'didnt',\n",
       " 'any',\n",
       " 'special',\n",
       " 'explain',\n",
       " 'important',\n",
       " 'stop',\n",
       " 'using',\n",
       " 'job',\n",
       " 'prepare',\n",
       " 'child',\n",
       " 'loss',\n",
       " 'favorite',\n",
       " 'item',\n",
       " 'doll',\n",
       " 'adorable',\n",
       " 'made',\n",
       " 'lots',\n",
       " 'cute',\n",
       " 'movies',\n",
       " 'telling',\n",
       " 'happens',\n",
       " 'comes',\n",
       " 'would',\n",
       " 'parent',\n",
       " 'trying',\n",
       " 'break',\n",
       " 'or',\n",
       " 'thumb',\n",
       " 'sucking',\n",
       " 'habit',\n",
       " 'lovely',\n",
       " 'its',\n",
       " 'bound',\n",
       " 'tightly',\n",
       " 'may',\n",
       " 'be',\n",
       " 'able',\n",
       " 'add',\n",
       " 'alot',\n",
       " 'photoscards',\n",
       " 'aside',\n",
       " 'designated',\n",
       " 'spaces',\n",
       " 'shop',\n",
       " 'around',\n",
       " 'before',\n",
       " 'as',\n",
       " 'currently',\n",
       " 'listed',\n",
       " 'at',\n",
       " 'barnes',\n",
       " 'noble',\n",
       " '2995',\n",
       " 'perfect',\n",
       " 'new',\n",
       " 'were',\n",
       " 'keep',\n",
       " 'track',\n",
       " 'babys',\n",
       " 'feeding',\n",
       " 'sleep',\n",
       " 'diaper',\n",
       " 'change',\n",
       " 'schedule',\n",
       " 'first',\n",
       " 'two',\n",
       " 'half',\n",
       " 'months',\n",
       " 'life',\n",
       " 'easier',\n",
       " 'doctor',\n",
       " 'ask',\n",
       " 'questions',\n",
       " 'habits',\n",
       " 'because',\n",
       " 'had',\n",
       " 'right',\n",
       " 'there',\n",
       " 'friend',\n",
       " 'mine',\n",
       " 'pinned',\n",
       " 'on',\n",
       " 'pinterest',\n",
       " 'decided',\n",
       " 'give',\n",
       " 'whirl',\n",
       " 'fantastic',\n",
       " 'if',\n",
       " 'are',\n",
       " 'feedings',\n",
       " 'changes',\n",
       " 'im',\n",
       " 'time',\n",
       " 'mom',\n",
       " 'definitely',\n",
       " 'moms',\n",
       " 'plus',\n",
       " 'small',\n",
       " 'enough',\n",
       " 'that',\n",
       " 'throw',\n",
       " 'visits',\n",
       " 'originally',\n",
       " 'just',\n",
       " 'gave',\n",
       " 'nanny',\n",
       " 'pad',\n",
       " 'paper',\n",
       " 'write',\n",
       " 'down',\n",
       " 'information',\n",
       " 'one',\n",
       " 'take',\n",
       " 'him',\n",
       " 'park',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'incompleteinaccurate',\n",
       " 'wohld',\n",
       " 'get',\n",
       " 'home',\n",
       " 'end',\n",
       " 'day',\n",
       " 'try',\n",
       " 'remember',\n",
       " 'napsfeedingsdiaper',\n",
       " 'wanted',\n",
       " 'something',\n",
       " 'could',\n",
       " 'also',\n",
       " 'better',\n",
       " 'control',\n",
       " 'reported',\n",
       " 'solution',\n",
       " 'helpful',\n",
       " 'example',\n",
       " 'fill',\n",
       " 'out',\n",
       " 'pouch',\n",
       " 'additional',\n",
       " 'documents',\n",
       " 'section',\n",
       " 'up',\n",
       " 'front',\n",
       " 'emergency',\n",
       " 'contact',\n",
       " 'info',\n",
       " 'each',\n",
       " 'page',\n",
       " 'goes',\n",
       " '7',\n",
       " '6',\n",
       " 'works',\n",
       " 'me',\n",
       " 'starts',\n",
       " '7am',\n",
       " 'ends',\n",
       " '6pm',\n",
       " 'use',\n",
       " 'app',\n",
       " 'phone',\n",
       " 'tracking',\n",
       " 'baby',\n",
       " 'transfer',\n",
       " 'notebook',\n",
       " 'only',\n",
       " 'complaint',\n",
       " 'space',\n",
       " 'pretty',\n",
       " 'they',\n",
       " 'provide',\n",
       " 'useful',\n",
       " 'shorthand',\n",
       " 'but',\n",
       " 'difficult',\n",
       " 'fit',\n",
       " 'some',\n",
       " 'provided',\n",
       " 'other',\n",
       " 'reviews',\n",
       " 'complain',\n",
       " 'format',\n",
       " 'isnt',\n",
       " 'real',\n",
       " 'problem',\n",
       " 'suppose',\n",
       " 'entire',\n",
       " 'pages',\n",
       " 'too',\n",
       " 'big',\n",
       " 'deal',\n",
       " 'daycarenannycaregiver',\n",
       " 'situation',\n",
       " 'monthly',\n",
       " 'photos',\n",
       " 'lot',\n",
       " 'stickers',\n",
       " 'come',\n",
       " 'exactly',\n",
       " 'bought',\n",
       " 'calender',\n",
       " 'myself',\n",
       " 'second',\n",
       " 'son',\n",
       " 'colorful',\n",
       " 'room',\n",
       " 'height',\n",
       " 'weight',\n",
       " 'likes',\n",
       " 'do',\n",
       " 'photo',\n",
       " 'placed',\n",
       " 'date',\n",
       " 'boxes',\n",
       " 'sticker',\n",
       " 'fine',\n",
       " 'writing',\n",
       " 'put',\n",
       " 'asterisks',\n",
       " 'whatever',\n",
       " 'event',\n",
       " 'happened',\n",
       " 'find',\n",
       " 'year',\n",
       " 'did',\n",
       " 'continue',\n",
       " 'cause',\n",
       " 'things',\n",
       " 'note',\n",
       " 'still',\n",
       " 'after',\n",
       " 'turn',\n",
       " '1',\n",
       " 'got',\n",
       " 'completed',\n",
       " 'calendar',\n",
       " 'sons',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'his',\n",
       " 'milestones',\n",
       " 'moments',\n",
       " 'since',\n",
       " 'hes',\n",
       " 'doing',\n",
       " 'amazing',\n",
       " 'fun',\n",
       " 'every',\n",
       " 'simple',\n",
       " 'layout',\n",
       " 'while',\n",
       " 'might',\n",
       " 'milestone',\n",
       " 'want',\n",
       " 'least',\n",
       " 'recording',\n",
       " 'those',\n",
       " 'childs',\n",
       " 'option',\n",
       " 'arent',\n",
       " 'choices',\n",
       " 'purchased',\n",
       " 'secondyear',\n",
       " 'lack',\n",
       " 'selection',\n",
       " 'available',\n",
       " 'calendars',\n",
       " 'general',\n",
       " 'ones',\n",
       " 'okay',\n",
       " 'finish',\n",
       " 'glossy',\n",
       " 'which',\n",
       " 'makes',\n",
       " 'hard',\n",
       " 'certain',\n",
       " 'pens',\n",
       " 'oldfashioned',\n",
       " 'hopefully',\n",
       " 'future',\n",
       " 'purchasers',\n",
       " 'events',\n",
       " 'plenty',\n",
       " '1st',\n",
       " 'loved',\n",
       " 'reocording',\n",
       " 'he',\n",
       " 'natures',\n",
       " 'lullabies',\n",
       " 'continuing',\n",
       " 'daily',\n",
       " 'record',\n",
       " 'keeping',\n",
       " 'wonderful',\n",
       " 'helped',\n",
       " 'think',\n",
       " 'thought',\n",
       " 'own',\n",
       " 'super',\n",
       " 'brat',\n",
       " 'either',\n",
       " 'gender',\n",
       " 'wife',\n",
       " 'options',\n",
       " 'mark',\n",
       " 'firsts',\n",
       " 'includes',\n",
       " 'borders',\n",
       " 'etc',\n",
       " 'scrap',\n",
       " 'booking',\n",
       " 'especially',\n",
       " 'who',\n",
       " 'dont',\n",
       " 'actually',\n",
       " 'sit',\n",
       " 'haul',\n",
       " 'ton',\n",
       " 'scrapbook',\n",
       " 'supplies',\n",
       " 'over',\n",
       " 'ago',\n",
       " 'receive',\n",
       " 'nearing',\n",
       " 'birthday',\n",
       " 'thanks',\n",
       " 'amazon',\n",
       " 'tender',\n",
       " 'sweet',\n",
       " 'art',\n",
       " 'unique',\n",
       " 'nice',\n",
       " 'keepsake',\n",
       " 'oneyear',\n",
       " 'old',\n",
       " 'extremely',\n",
       " 'tired',\n",
       " 'inexpedient',\n",
       " 'remembering',\n",
       " 'long',\n",
       " 'ate',\n",
       " 'through',\n",
       " 'hook',\n",
       " 'attach',\n",
       " 'stroller',\n",
       " 'car',\n",
       " 'seat',\n",
       " 'wont',\n",
       " 'lost',\n",
       " 'go',\n",
       " 'family',\n",
       " 'members',\n",
       " 'beautiful',\n",
       " 'short',\n",
       " 'story',\n",
       " 'saying',\n",
       " 'youkeeps',\n",
       " 'attention',\n",
       " 'then',\n",
       " 'can',\n",
       " 'hold',\n",
       " 'finished',\n",
       " 'interacting',\n",
       " 'money',\n",
       " 'says',\n",
       " '9',\n",
       " 'box',\n",
       " 'cant',\n",
       " 'wait',\n",
       " 'born',\n",
       " 'interactive',\n",
       " 'flaps',\n",
       " 'open',\n",
       " 'oneyearold',\n",
       " 'bite',\n",
       " 'chunks',\n",
       " 'board',\n",
       " 'rip',\n",
       " 'chew',\n",
       " 'pull',\n",
       " 'carry',\n",
       " 'learning',\n",
       " 'words',\n",
       " 'daddy',\n",
       " 'mommy',\n",
       " 'puppy',\n",
       " '6months',\n",
       " 'older',\n",
       " 'thing',\n",
       " 'strong',\n",
       " 'smell',\n",
       " 'dyes',\n",
       " 'andor',\n",
       " 'material',\n",
       " 'dunked',\n",
       " 'detergent',\n",
       " 'let',\n",
       " 'dry',\n",
       " 'overnight',\n",
       " 'babies',\n",
       " 'id',\n",
       " 'been',\n",
       " 'books',\n",
       " 'couldnt',\n",
       " 'damaged',\n",
       " 'by',\n",
       " '10month',\n",
       " 'olds',\n",
       " 'droolso',\n",
       " 'cloth',\n",
       " 'plastic',\n",
       " 'adds',\n",
       " 'another',\n",
       " 'level',\n",
       " 'usual',\n",
       " 'booka',\n",
       " 'flap',\n",
       " 'moving',\n",
       " 'brushing',\n",
       " 'elmos',\n",
       " 'teeth',\n",
       " 'almost',\n",
       " 'play',\n",
       " 'haha',\n",
       " 'present',\n",
       " '2',\n",
       " 'grandchildren',\n",
       " 'themselves',\n",
       " 'pictures',\n",
       " 'imaginative',\n",
       " 'appeal',\n",
       " 'young',\n",
       " 'children',\n",
       " 'again',\n",
       " 'absolutely',\n",
       " 'elmo',\n",
       " 'seemed',\n",
       " 'happy',\n",
       " 'say',\n",
       " 'beautifully',\n",
       " 'illustrated',\n",
       " 'takes',\n",
       " 'everywhere',\n",
       " 'reads',\n",
       " 'main',\n",
       " 'character',\n",
       " 'hides',\n",
       " 'sesame',\n",
       " 'street',\n",
       " 'characters',\n",
       " 'featured',\n",
       " 'centric',\n",
       " 'streetelmo',\n",
       " 'lovers',\n",
       " 'twinkle',\n",
       " 'price',\n",
       " 'birds',\n",
       " 'friends',\n",
       " 'softplay',\n",
       " 'bird',\n",
       " 'more',\n",
       " 'variety',\n",
       " 'creative',\n",
       " 'peekaboo',\n",
       " 'safe',\n",
       " 'handle',\n",
       " '3',\n",
       " 'month',\n",
       " 'read',\n",
       " 'smiles',\n",
       " 'laughs',\n",
       " '34peekaboo',\n",
       " 'elmo34',\n",
       " 'few',\n",
       " 'different',\n",
       " 'adores',\n",
       " '5',\n",
       " 'stars',\n",
       " 'sure',\n",
       " 'bright',\n",
       " 'illustrations',\n",
       " 'make',\n",
       " 'toddlers',\n",
       " 'granddauchildren',\n",
       " 'reading',\n",
       " 'fall',\n",
       " 'kiss',\n",
       " 'mos',\n",
       " 'having',\n",
       " 'see',\n",
       " 'high',\n",
       " 'stack',\n",
       " 'blocks',\n",
       " 'falls',\n",
       " 'teething',\n",
       " 'these',\n",
       " 'entertaining',\n",
       " 'letting',\n",
       " 'droll',\n",
       " 'without',\n",
       " 'worrying',\n",
       " 'ruining',\n",
       " 'setting',\n",
       " 'side',\n",
       " 'encourage',\n",
       " 'rolling',\n",
       " 'crawling',\n",
       " 'christmas',\n",
       " 'younger',\n",
       " 'bank',\n",
       " 'boring',\n",
       " 'nothing',\n",
       " 'stimulate',\n",
       " 'granddaughter',\n",
       " 'waste',\n",
       " 'actual',\n",
       " 'images',\n",
       " 'unrealistic',\n",
       " 'portrayals',\n",
       " 'animalsobjects',\n",
       " 'look',\n",
       " 'forwhen',\n",
       " 'teach',\n",
       " 'lion',\n",
       " 'show',\n",
       " 'drawing',\n",
       " 'looks',\n",
       " 'cuteso',\n",
       " '34',\n",
       " 'read34',\n",
       " 'no',\n",
       " 'chance',\n",
       " 'destroyingmany',\n",
       " 'memories',\n",
       " 'momento',\n",
       " 'quick',\n",
       " 'busy',\n",
       " 'firsttime',\n",
       " 'good',\n",
       " 'mother',\n",
       " 'soon',\n",
       " 'start',\n",
       " 'beginning',\n",
       " '34firsts34',\n",
       " 'five',\n",
       " 'enjoy',\n",
       " 'law',\n",
       " 'place',\n",
       " 'verses',\n",
       " 'bottom',\n",
       " 'omgwe',\n",
       " 'gets',\n",
       " 'bigger',\n",
       " 'asking',\n",
       " 'even',\n",
       " 'foot',\n",
       " 'hand',\n",
       " 'prints',\n",
       " 'reason',\n",
       " 'why',\n",
       " 'liked',\n",
       " 'pockets',\n",
       " 'keepsakes',\n",
       " 'places',\n",
       " 'locks',\n",
       " 'hairetc',\n",
       " 'shower',\n",
       " 'cherished',\n",
       " 'times',\n",
       " 'granddaughters',\n",
       " 'pastel',\n",
       " 'pink',\n",
       " 'color',\n",
       " 'english',\n",
       " 'french',\n",
       " 'flammish',\n",
       " 'firstsand',\n",
       " 'mini',\n",
       " 'preserve',\n",
       " 'hair',\n",
       " 'maternity',\n",
       " 'braceletreally',\n",
       " 'pleasantly',\n",
       " 'surprised',\n",
       " 'upon',\n",
       " 'receiving',\n",
       " 'memory',\n",
       " 'entitled',\n",
       " 'kindergarten',\n",
       " 'experience',\n",
       " 'photographs',\n",
       " 'detailed',\n",
       " 'descriptions',\n",
       " 'answer',\n",
       " 'serving',\n",
       " 'purpose',\n",
       " 'parentid',\n",
       " 'everyone',\n",
       " 'kindergartener',\n",
       " 'glad',\n",
       " 'stumbled',\n",
       " 'gem',\n",
       " 'already',\n",
       " 'started',\n",
       " 'answering',\n",
       " 'years',\n",
       " 'later',\n",
       " 'answered',\n",
       " 'elephant',\n",
       " 'neat',\n",
       " 'realization',\n",
       " 'association',\n",
       " 'between',\n",
       " 'stuffed',\n",
       " 'toy',\n",
       " 'gives',\n",
       " 'light',\n",
       " 'used',\n",
       " 'yearsi',\n",
       " 'spring',\n",
       " 'project',\n",
       " 'affordable',\n",
       " 'wall',\n",
       " 'decals',\n",
       " 'quality',\n",
       " 'brightens',\n",
       " 'reasonsmall',\n",
       " 'sizehard',\n",
       " 'apply',\n",
       " 'flower',\n",
       " 'pieceyou',\n",
       " 'know',\n",
       " 'morning',\n",
       " 'flowers',\n",
       " 'fell',\n",
       " 'floor',\n",
       " 'roll',\n",
       " 'winnie',\n",
       " 'pooh',\n",
       " 'themed',\n",
       " 'decor',\n",
       " 'zealand',\n",
       " 'cost',\n",
       " 'effective',\n",
       " 'impressed',\n",
       " 'stick',\n",
       " '34look34',\n",
       " 'professional',\n",
       " 'seamless',\n",
       " 'paintwork',\n",
       " 'satisfied',\n",
       " 'grat',\n",
       " 'design',\n",
       " 'ir',\n",
       " 'said',\n",
       " 'reccomend',\n",
       " 'follow',\n",
       " 'buying',\n",
       " 'divine',\n",
       " 'mercy',\n",
       " 'pendant',\n",
       " 'jesus',\n",
       " 'chain',\n",
       " 'neck',\n",
       " 'represents',\n",
       " 'jesuswho',\n",
       " 'offers',\n",
       " 'us',\n",
       " 'ocean',\n",
       " 'pray',\n",
       " 'god',\n",
       " 'country',\n",
       " 'need',\n",
       " 'lives',\n",
       " 'reusable',\n",
       " 'clean',\n",
       " 'during',\n",
       " 'ill',\n",
       " 'million',\n",
       " 'uses',\n",
       " 'days',\n",
       " 'done',\n",
       " 'ordering',\n",
       " 'bit',\n",
       " 'smaller',\n",
       " 'fault',\n",
       " 'taking',\n",
       " 'measurements',\n",
       " 'pins',\n",
       " 'autistic',\n",
       " 'normal',\n",
       " 'safety',\n",
       " 'needed',\n",
       " 'night',\n",
       " 'clothes',\n",
       " 'significantly',\n",
       " 'sturdy',\n",
       " 'hasnt',\n",
       " 'learned',\n",
       " 'once',\n",
       " 'broken',\n",
       " 'seem',\n",
       " 'recall',\n",
       " 'shipping',\n",
       " 'reasonable',\n",
       " 'though',\n",
       " 'given',\n",
       " 'package',\n",
       " 'qualityworked',\n",
       " 'fineheavy',\n",
       " 'dutyable',\n",
       " 'filled',\n",
       " 'others',\n",
       " 'pin',\n",
       " 'colors',\n",
       " 'bargain',\n",
       " 'dozen',\n",
       " 'attractive',\n",
       " 'metal',\n",
       " 'received',\n",
       " 'flimsy',\n",
       " 'thick',\n",
       " 'fabric',\n",
       " 'fortunately',\n",
       " 'involved',\n",
       " 'stuck',\n",
       " 'went',\n",
       " 'honduras',\n",
       " 'diapers',\n",
       " 'sent',\n",
       " 'missionaries',\n",
       " '34disposable34',\n",
       " 'age',\n",
       " '34pampers34',\n",
       " 'appreciated',\n",
       " 'kits',\n",
       " 'socks',\n",
       " 'together',\n",
       " 'wash',\n",
       " 'never',\n",
       " 'yet',\n",
       " 'brass',\n",
       " 'dressmaker',\n",
       " 'tended',\n",
       " 'cycle',\n",
       " 'suggested',\n",
       " 'theryre',\n",
       " 'working',\n",
       " 'perfectly',\n",
       " 'staying',\n",
       " 'washing',\n",
       " 'matter',\n",
       " 'fact',\n",
       " 'tricky',\n",
       " 'course',\n",
       " 'idea',\n",
       " 'recommended',\n",
       " '34friended',\n",
       " 'up34',\n",
       " 'reviewer',\n",
       " 'noted',\n",
       " 'matching',\n",
       " 'washer',\n",
       " 'hang',\n",
       " 'stay',\n",
       " 'line',\n",
       " 'clothespins',\n",
       " 'sock',\n",
       " 'dried',\n",
       " 'hamper',\n",
       " 'shelf',\n",
       " 'dirty',\n",
       " 'into',\n",
       " 'grab',\n",
       " 'saved',\n",
       " 'mismatched',\n",
       " 'feet',\n",
       " 'am',\n",
       " 'here',\n",
       " 'wish',\n",
       " 'whole',\n",
       " 'steel',\n",
       " 'unlike',\n",
       " 'thicker',\n",
       " 'pinsturns',\n",
       " 'should',\n",
       " 'counted',\n",
       " 'pictureas',\n",
       " '10',\n",
       " 'sadand',\n",
       " 'overpriced',\n",
       " 'yarn',\n",
       " 'crochet',\n",
       " 'regular',\n",
       " 'sharp',\n",
       " 'pierce',\n",
       " 'dislike',\n",
       " 'sides',\n",
       " 'bend',\n",
       " 'pain',\n",
       " 'pushing',\n",
       " 'velcro',\n",
       " 'tabs',\n",
       " 'doesnt',\n",
       " 'anymore',\n",
       " 'locally',\n",
       " 'peel',\n",
       " 'ordered',\n",
       " 'rosary',\n",
       " 'looked',\n",
       " 'blessed',\n",
       " 'pope',\n",
       " 'francis',\n",
       " 'crystal',\n",
       " 'knotted',\n",
       " 'fathers',\n",
       " 'giving',\n",
       " 'along',\n",
       " 'copy',\n",
       " 'novena',\n",
       " 'lady',\n",
       " 'untier',\n",
       " 'undoer',\n",
       " 'knots',\n",
       " 'whom',\n",
       " 'devotion',\n",
       " 'heart',\n",
       " 'beat',\n",
       " 'excellent',\n",
       " 'value',\n",
       " 'wearing',\n",
       " 'orattaching',\n",
       " 'brown',\n",
       " 'scapular',\n",
       " 'such',\n",
       " 'blessing',\n",
       " 'precious',\n",
       " 'pleased',\n",
       " 'bangles',\n",
       " 'however',\n",
       " 'slid',\n",
       " 'lotion',\n",
       " 'snug',\n",
       " 'fitting',\n",
       " 'bangle',\n",
       " 'whew',\n",
       " 'tough',\n",
       " 'wouldnt',\n",
       " 'hands',\n",
       " 'large',\n",
       " 'kid',\n",
       " 'adult',\n",
       " 'wrist',\n",
       " 'overall',\n",
       " 'fast',\n",
       " 'yr',\n",
       " 'playing',\n",
       " 'set',\n",
       " 'pretend',\n",
       " 'cooking',\n",
       " 'bibs',\n",
       " 'awesome',\n",
       " 'protections',\n",
       " 'messy',\n",
       " 'eaters',\n",
       " 'grandson',\n",
       " '20',\n",
       " 'boy',\n",
       " 'eat',\n",
       " 'marinara',\n",
       " 'pasta',\n",
       " 'fingers',\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>new_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>1.363690</td>\n",
       "      <td>0.251931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.068691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>easy</td>\n",
       "      <td>1.192538</td>\n",
       "      <td>-0.004988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.085513</td>\n",
       "      <td>0.008205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>0.520186</td>\n",
       "      <td>-0.294920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perfect</td>\n",
       "      <td>1.509812</td>\n",
       "      <td>-0.616341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.673074</td>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>0.503760</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>0.190909</td>\n",
       "      <td>0.207305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>0.058855</td>\n",
       "      <td>0.050010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  coefficient  new_coefficient\n",
       "0     love     1.363690         0.251931\n",
       "1    great     0.944000         0.068691\n",
       "2     easy     1.192538        -0.004988\n",
       "3      old     0.085513         0.008205\n",
       "4   little     0.520186        -0.294920\n",
       "5  perfect     1.509812        -0.616341\n",
       "6    loves     1.673074         0.008729\n",
       "7     well     0.503760         0.000018\n",
       "8     able     0.190909         0.207305\n",
       "9      car     0.058855         0.050010"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = {vocab[i]: c for i, c in enumerate(sentiment_model.coef_[0])}\n",
    "new_dic = {k:v for k, v in coeffs.items() if k in significant_words}\n",
    "new_table = pd.DataFrame(new_dic.items(), columns=['word', 'new_coefficient'])\n",
    "new_table_coeff = pd.merge(simple_model_coef_table, new_table, how = 'left', on = 'word' )\n",
    "new_table_coeff = new_table_coeff[new_table_coeff['coefficient']>=0].copy(deep=True)\n",
    "print(sum(new_table_coeff['new_coefficient'] < 0))\n",
    "new_table_coeff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing models\n",
    "We will now compare the accuracy of the sentiment_model and the simple_model.\n",
    "\n",
    "First, compute the classification accuracy of the sentiment_model on the train_data.\n",
    "\n",
    "Now, compute the classification accuracy of the simple_model on the train_data.\n",
    "\n",
    "the accuracy of the sentiment_model and the simple mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sentiment_train_sentiment = sentiment_model.predict(train_matrix)\n",
    "train_data['predicted_sentiment_ts'] = predicted_sentiment_train_sentiment\n",
    "acc_ts = round(float(sum(train_data['predicted_sentiment_ts'] == train_data['sentiment']))/len(train_data.index),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_simple_train_sentiment = simple_model.predict(train_matrix_word_subset)\n",
    "train_data['predicted_simple_ts'] = predicted_simple_train_sentiment\n",
    "acc_tsimple = round(float(sum(train_data['predicted_simple_ts'] == train_data['sentiment']))/len(train_data.index),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_ts > acc_tsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_tsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the accuracy of the sentiment_model and the simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentiment_test_sentiment = sentiment_model.predict(test_matrix)\n",
    "test_data['predicted_sentiment_ts'] = predicted_sentiment_test_sentiment\n",
    "acc_ts_test = round(float(sum(test_data['predicted_sentiment_ts'] == test_data['sentiment']))/len(test_data.index),2)\n",
    "acc_ts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_simple_test_sentiment = simple_model.predict(test_matrix_word_subset)\n",
    "test_data['predicted_simple_ts'] = predicted_simple_test_sentiment\n",
    "acc_tsimple_test = round(float(sum(test_data['predicted_simple_ts'] == test_data['sentiment']))/len(test_data.index),2)\n",
    "acc_tsimple_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_ts_test > acc_tsimple_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The majority class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Sentiments: 112164\n",
      "Total Negative Sentiments: 21252\n"
     ]
    }
   ],
   "source": [
    "print (\"Total Positive Sentiments: {}\".format(sum(train_data['sentiment'] == 1)))\n",
    "print (\"Total Negative Sentiments: {}\".format(sum(train_data['sentiment'] == -1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(sum(test_data['sentiment'] ==1))/len(test_data.index),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
